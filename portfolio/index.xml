<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Portfolios on Kate Lyons</title>
    <link>/portfolio/index.xml</link>
    <description>Recent content in Portfolios on Kate Lyons</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy;2017 Kate Lyons</copyright>
    <lastBuildDate>Sat, 05 Nov 2016 18:25:22 +0530</lastBuildDate>
    <atom:link href="/portfolio/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Name of the work 1</title>
      <link>/portfolio/work1/</link>
      <pubDate>Sat, 05 Nov 2016 18:25:22 +0530</pubDate>
      
      <guid>/portfolio/work1/</guid>
      <description>&lt;p&gt;Even the all-powerful Pointing has no control about the blind texts it is an almost unorthographic life. One day however a small line of blind text by the name of Lorem Ipsum decided to leave for the far World of Grammar.
&lt;/p&gt;

&lt;p&gt;Far far away, behind the word mountains, far from the countries Vokalia and Consonantia, there live the blind texts. Separated they live in Bookmarksgrove right at the coast of the Semantics, a large language ocean.&lt;/p&gt;

&lt;p&gt;A small river named Duden flows by their place and supplies it with the necessary regelialia. It is a paradisematic country, in which roasted parts of sentences fly into your mouth.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;header-level-2&#34;&gt;Header Level 2&lt;/h2&gt;

&lt;p&gt;Even the all-powerful Pointing has no control about the blind texts it is an almost unorthographic life One day however a small line of blind text by the name of Lorem Ipsum decided to leave for the far World of Grammar.&lt;/p&gt;

&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When she reached the first hills of the Italic Mountains, she had a last view back on the skyline of her hometown Bookmarksgrove, the headline of Alphabet Village and the subline of her own road, the Line Lane. Pityful a rethoric question ran over her cheek, then&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Name of the work 2</title>
      <link>/portfolio/work2/</link>
      <pubDate>Sat, 05 Nov 2016 19:41:01 +0530</pubDate>
      
      <guid>/portfolio/work2/</guid>
      <description>&lt;p&gt;When she reached the first hills of the Italic Mountains, she had a last view back on the skyline of her hometown Bookmarksgrove, the headline of Alphabet Village and the subline of her own road, the Line Lane.
&lt;/p&gt;

&lt;p&gt;Far far away, behind the word mountains, far from the countries Vokalia and Consonantia, there live the blind texts. Separated they live in Bookmarksgrove right at the coast of the Semantics, a large language ocean.&lt;/p&gt;

&lt;p&gt;A small river named Duden flows by their place and supplies it with the necessary regelialia. It is a paradisematic country, in which roasted parts of sentences fly into your mouth.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;header-level-2&#34;&gt;Header Level 2&lt;/h2&gt;

&lt;p&gt;Even the all-powerful Pointing has no control about the blind texts it is an almost unorthographic life One day however a small line of blind text by the name of Lorem Ipsum decided to leave for the far World of Grammar.&lt;/p&gt;

&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When she reached the first hills of the Italic Mountains, she had a last view back on the skyline of her hometown Bookmarksgrove, the headline of Alphabet Village and the subline of her own road, the Line Lane. Pityful a rethoric question ran over her cheek, then&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Having Fun with Tidy Text!</title>
      <link>/portfolio/2017-03-09-fun-w-tidy-text/</link>
      <pubDate>Thu, 23 Jul 2015 21:13:14 -0500</pubDate>
      
      <guid>/portfolio/2017-03-09-fun-w-tidy-text/</guid>
      <description>&lt;p&gt;Julia Silge and David Robinson have a wonderful new book called “Text Mining with R” which has a &lt;a href=&#34;http://tidytextmining.com/&#34;&gt;companion website&lt;/a&gt; with great explanations and examples. Here are some additional applications of those examples on a corpus of geotagged Instagram posts from the Mission District neighborhood in San Francisco.&lt;/p&gt;


&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Make sure you have the right packages!
packs = c(&amp;quot;twitteR&amp;quot;,&amp;quot;RCurl&amp;quot;,&amp;quot;RJSONIO&amp;quot;,&amp;quot;stringr&amp;quot;,&amp;quot;ggplot2&amp;quot;,&amp;quot;devtools&amp;quot;,&amp;quot;DataCombine&amp;quot;,&amp;quot;ggmap&amp;quot;,
          &amp;quot;topicmodels&amp;quot;,&amp;quot;slam&amp;quot;,&amp;quot;Rmpfr&amp;quot;,&amp;quot;tm&amp;quot;,&amp;quot;stringr&amp;quot;,&amp;quot;wordcloud&amp;quot;,&amp;quot;plyr&amp;quot;,
          &amp;quot;tidytext&amp;quot;,&amp;quot;dplyr&amp;quot;,&amp;quot;tidyr&amp;quot;,&amp;quot;xlsx&amp;quot;,&amp;quot;scales&amp;quot;,&amp;quot;ggrepel&amp;quot;,&amp;quot;lubridate&amp;quot;,&amp;quot;purrr&amp;quot;,&amp;quot;broom&amp;quot;)
lapply(packs, library, character.only=T)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data need to be processed a bit more in order to analyze them. Let’s try from the start with &lt;a href=&#34;http://tidytextmining.com/&#34;&gt;Silge and Robinson&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Get rid of stuff particular to the data (here encodings of links and such)
# Most of these are characters I don&amp;#39;t have encodings for (other scripts, etc.)
tweets$text = gsub(&amp;quot;Just posted a photo&amp;quot;,&amp;quot;&amp;quot;, tweets$text)
tweets$text = gsub( &amp;quot;&amp;lt;.*?&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, tweets$text)

# Get rid of super frequent spam posters
tweets &amp;lt;- tweets[! tweets$screenName %in% c(&amp;quot;4AMSOUNDS&amp;quot;,
      &amp;quot;BruciusTattoo&amp;quot;,&amp;quot;LionsHeartSF&amp;quot;,&amp;quot;hermesalchemist&amp;quot;,&amp;quot;Mrsourmash&amp;quot;),]


# Now for Silge and Robinson&amp;#39;s code. What this is doing is getting rid of URLs, re-tweets (RT) and ampersands. This also gets rid of stop words without having to get rid of hashtags and @ signs by using str_detect and filter! 
reg &amp;lt;- &amp;quot;([^A-Za-z_\\d#@&amp;#39;]|&amp;#39;(?![A-Za-z_\\d#@]))&amp;quot;
tidy_tweets &amp;lt;- tweets %&amp;gt;% 
  filter(!str_detect(text, &amp;quot;^RT&amp;quot;)) %&amp;gt;%
  mutate(text = str_replace_all(text, &amp;quot;https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;amp;amp;|&amp;amp;lt;|&amp;amp;gt;|RT|https&amp;quot;, &amp;quot;&amp;quot;)) %&amp;gt;%
  unnest_tokens(word, text, token = &amp;quot;regex&amp;quot;, pattern = reg) %&amp;gt;%
  filter(!word %in% stop_words$word,
         str_detect(word, &amp;quot;[a-z]&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Awesome! Now our posts are cleaned with the hashtags and @ mentions still intact. What we can try now is to plot the frequency of some of these terms according to WHERE they occur. Silge and Robinson have an example with persons, let’s try with coordinates.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;freq &amp;lt;- tidy_tweets %&amp;gt;% 
  group_by(latitude,longitude) %&amp;gt;% 
  count(word, sort = TRUE) %&amp;gt;% 
  left_join(tidy_tweets %&amp;gt;% 
              group_by(latitude,longitude) %&amp;gt;% 
              summarise(total = n())) %&amp;gt;%
  mutate(freq = n/total)

freq&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source: local data frame [61,008 x 6]
## Groups: latitude, longitude [1,411]
## 
##    latitude longitude          word     n total       freq
##       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;         &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;      &amp;lt;dbl&amp;gt;
## 1  37.76000 -122.4200       mission  1844 21372 0.08628112
## 2  37.76000 -122.4200           san  1592 21372 0.07448999
## 3  37.76000 -122.4200      district  1576 21372 0.07374134
## 4  37.76000 -122.4200     francisco  1464 21372 0.06850084
## 5  37.75833 -122.4275          park   293  2745 0.10673953
## 6  37.75833 -122.4275       mission   285  2745 0.10382514
## 7  37.75833 -122.4275       dolores   278  2745 0.10127505
## 8  37.76000 -122.4200 #sanfrancisco   275 21372 0.01286730
## 9  37.76300 -122.4209         alley   245  2273 0.10778707
## 10 37.76300 -122.4209       clarion   242  2273 0.10646722
## # ... with 60,998 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The n here is the total number of times this term has shown up, and the total is how many terms there are present in a particular coordinate.&lt;/p&gt;
&lt;p&gt;Cool! Now we have a representation of terms, their frequency and their position. Now I might want to plot this somehow… one way would be to try to plot the most frequent terms (n &amp;gt; 50) (Some help on how to do this was taken from &lt;a href=&#34;http://blog.revolutionanalytics.com/2016/01/avoid-overlapping-labels-in-ggplot2-charts.html&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;http://stackoverflow.com/questions/14288001/geom-text-not-working-when-ggmap-and-geom-point-used&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;freq2 &amp;lt;- subset(freq, n &amp;gt; 50) 

map &amp;lt;- get_map(location = &amp;#39;Valencia St. and 20th, San Francisco,
               California&amp;#39;, zoom = 15)

freq2$longitude&amp;lt;-as.numeric(freq2$longitude)
freq2$latitude&amp;lt;-as.numeric(freq2$latitude)
lon &amp;lt;- freq2$longitude
lat &amp;lt;- freq2$latitude

mapPoints &amp;lt;- ggmap(map) + geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
  geom_label_repel(data = freq2, aes(x = lon, y = lat, label = word),size = 2) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/portfolio/2017-03-09-fun-w-tidy-text_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let’s zoom into that main central area to see what’s going on!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;map2 &amp;lt;- get_map(location = &amp;#39;Lexington St. and 19th, San Francisco,
               California&amp;#39;, zoom = 16)
mapPoints2 &amp;lt;- ggmap(map2) + geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
  geom_label_repel(data = freq2, aes(x = lon, y = lat, label = word),size = 2) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/portfolio/2017-03-09-fun-w-tidy-text_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This can be manipulated in many different ways – either by playing with what frequency of terms you want to look at (maybe I want to see terms that occur 100 times, between 20 and 50 times, less than 20 times etc. etc.) OR by playing around with the map. At the moment though, this is pretty illuminating in the sense that it shows us that the most frequency terms are focused around certain ‘hotspots’ in the area, which in itself is just kind of cool to see.&lt;/p&gt;
&lt;p&gt;Now let’s try out word frequency changes over time: what words were used more or less over the time of data collection? (Help from &lt;a href=&#34;http://tidytextmining.com/twitter.html&#34;&gt;here&lt;/a&gt;) (Also used the &lt;a href=&#34;https://cran.r-project.org/web/packages/lubridate/lubridate.pdf&#34;&gt;lubridate package&lt;/a&gt; to help with time.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Might have to do this first
tidy_tweets$created2 &amp;lt;- as.POSIXct(tidy_tweets$created, format=&amp;quot;%m/%d/%Y %H:%M&amp;quot;)

words_by_time &amp;lt;- tidy_tweets %&amp;gt;%
  mutate(time_floor = floor_date(created2, unit = &amp;quot;1 week&amp;quot;)) %&amp;gt;%
  count(time_floor, word) %&amp;gt;%
  ungroup() %&amp;gt;%
  group_by(time_floor) %&amp;gt;%
  mutate(time_total = sum(n)) %&amp;gt;%
  group_by(word) %&amp;gt;%
  mutate(word_total = sum(n)) %&amp;gt;%
  ungroup() %&amp;gt;%
  rename(count = n) %&amp;gt;%
  filter(word_total &amp;gt; 100)

words_by_time&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1,979 × 5
##    time_floor             word count time_total word_total
##        &amp;lt;dttm&amp;gt;            &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt;      &amp;lt;int&amp;gt;      &amp;lt;int&amp;gt;
## 1  0016-07-31             #art     7       2729        120
## 2  0016-07-31      #california     9       2729        149
## 3  0016-07-31     #dolorespark     6       2729        168
## 4  0016-07-31         #mission     5       2729        222
## 5  0016-07-31 #missiondistrict     1       2729        158
## 6  0016-07-31    #sanfrancisco    38       2729       1034
## 7  0016-07-31              #sf    23       2729        603
## 8  0016-07-31       #streetart    12       2729        229
## 9  0016-07-31             24th    10       2729        109
## 10 0016-07-31            alamo     3       2729        111
## # ... with 1,969 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alright, now we want to figure out those words that have changed the most in their frequency over time so as to isolate ones of interests to plot over time. This involves a few steps though.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nested_data &amp;lt;- words_by_time %&amp;gt;%
  nest(-word) 
nested_data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 71 × 2
##                word              data
##               &amp;lt;chr&amp;gt;            &amp;lt;list&amp;gt;
## 1              #art &amp;lt;tibble [26 × 4]&amp;gt;
## 2       #california &amp;lt;tibble [28 × 4]&amp;gt;
## 3      #dolorespark &amp;lt;tibble [27 × 4]&amp;gt;
## 4          #mission &amp;lt;tibble [28 × 4]&amp;gt;
## 5  #missiondistrict &amp;lt;tibble [29 × 4]&amp;gt;
## 6     #sanfrancisco &amp;lt;tibble [29 × 4]&amp;gt;
## 7               #sf &amp;lt;tibble [29 × 4]&amp;gt;
## 8        #streetart &amp;lt;tibble [28 × 4]&amp;gt;
## 9              24th &amp;lt;tibble [28 × 4]&amp;gt;
## 10            alamo &amp;lt;tibble [27 × 4]&amp;gt;
## # ... with 61 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Process as described by Silge and Robinson: “This data frame has one row for each person-word combination; the data column is a list column that contains data frames, one for each combination of person and word. Let’s use map() from the purrr library to apply our modeling procedure to each of those little data frames inside our big data frame. This is count data so let’s use glm() with family =”binomial&amp;quot; for modeling. We can think about this modeling procedure answering a question like, “Was a given word mentioned in a given time bin? Yes or no? How does the count of word mentions depend on time?”&amp;quot;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nested_models &amp;lt;- nested_data %&amp;gt;%
  mutate(models = map(data, ~ glm(cbind(count, time_total) ~ time_floor, ., 
                                  family = &amp;quot;binomial&amp;quot;)))

nested_models&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 71 × 3
##                word              data    models
##               &amp;lt;chr&amp;gt;            &amp;lt;list&amp;gt;    &amp;lt;list&amp;gt;
## 1              #art &amp;lt;tibble [26 × 4]&amp;gt; &amp;lt;S3: glm&amp;gt;
## 2       #california &amp;lt;tibble [28 × 4]&amp;gt; &amp;lt;S3: glm&amp;gt;
## 3      #dolorespark &amp;lt;tibble [27 × 4]&amp;gt; &amp;lt;S3: glm&amp;gt;
## 4          #mission &amp;lt;tibble [28 × 4]&amp;gt; &amp;lt;S3: glm&amp;gt;
## 5  #missiondistrict &amp;lt;tibble [29 × 4]&amp;gt; &amp;lt;S3: glm&amp;gt;
## 6     #sanfrancisco &amp;lt;tibble [29 × 4]&amp;gt; &amp;lt;S3: glm&amp;gt;
## 7               #sf &amp;lt;tibble [29 × 4]&amp;gt; &amp;lt;S3: glm&amp;gt;
## 8        #streetart &amp;lt;tibble [28 × 4]&amp;gt; &amp;lt;S3: glm&amp;gt;
## 9              24th &amp;lt;tibble [28 × 4]&amp;gt; &amp;lt;S3: glm&amp;gt;
## 10            alamo &amp;lt;tibble [27 × 4]&amp;gt; &amp;lt;S3: glm&amp;gt;
## # ... with 61 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Silge and Robinson: “Now notice that we have a new column for the modeling results; it is another list column and contains glm objects. The next step is to use map() and tidy() from the broom package to pull out the slopes for each of these models and find the important ones. We are comparing many slopes here and some of them are not statistically significant, so let’s apply an adjustment to the p-values for multiple comparisons.”&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;slopes &amp;lt;- nested_models %&amp;gt;%
  unnest(map(models, tidy)) %&amp;gt;%
  filter(term == &amp;quot;time_floor&amp;quot;) %&amp;gt;%
  mutate(adjusted.p.value = p.adjust(p.value))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;“Now let’s find the most important slopes. Which words have changed in frequency at a moderately significant level in our tweets?”&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;top_slopes &amp;lt;- slopes %&amp;gt;% 
  filter(adjusted.p.value &amp;lt; 0.1)

top_slopes&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 16 × 7
##             word       term      estimate    std.error  statistic
##            &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;         &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
## 1   #dolorespark time_floor -1.239208e-07 1.877375e-08  -6.600749
## 2  #sanfrancisco time_floor -3.211771e-08 6.679608e-09  -4.808322
## 3            #sf time_floor -3.483812e-08 8.745735e-09  -3.983441
## 4          alley time_floor -7.976653e-08 1.277341e-08  -6.244732
## 5        clarion time_floor -9.680816e-08 1.449039e-08  -6.680855
## 6       district time_floor  6.701575e-08 5.346673e-09  12.534102
## 7        dolores time_floor -1.132466e-07 7.718189e-09 -14.672698
## 8      francisco time_floor  4.515439e-08 4.642235e-09   9.726865
## 9    manufactory time_floor -7.442008e-08 1.672651e-08  -4.449228
## 10       mission time_floor  3.625027e-08 3.999962e-09   9.062656
## 11          park time_floor -1.134007e-07 7.699185e-09 -14.728916
## 12           san time_floor  4.009249e-08 4.369834e-09   9.174832
## 13            sf time_floor -9.883069e-08 7.359724e-09 -13.428586
## 14        street time_floor -5.396273e-08 1.121572e-08  -4.811349
## 15       tartine time_floor -6.296002e-08 1.209275e-08  -5.206427
## 16      valencia time_floor -8.125194e-08 2.093658e-08  -3.880859
## # ... with 2 more variables: p.value &amp;lt;dbl&amp;gt;, adjusted.p.value &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s plot them!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;words_by_time %&amp;gt;%
  inner_join(top_slopes, by = c(&amp;quot;word&amp;quot;)) %&amp;gt;%
  ggplot(aes(time_floor, count/time_total, color = word)) +
  geom_line(size = 1.3) +
  labs(x = NULL, y = &amp;quot;Word frequency&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/portfolio/2017-03-09-fun-w-tidy-text_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;After looking at some of these features of our data set, it’s time to explore TOPIC MODELING, or (paraphrasing from David Blei) finding structure in more-or-less unstructured documents. To do this we need a document-term matrix. At the moment, the tweets are a little problematic in that they are broken up by words… whereas we actually would like the text of the tweet back as that is what we are treating as our ‘document’. The question at the moment is… do we want to keep the hashtags / can we?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Let&amp;#39;s try by taking our tweets that have been tidied already. First we need to count each word though, and create some kind of column that has 
# This first one is helpful for seeing encodings that need to be removed
tidy_tweets %&amp;gt;%
  count(document, word, sort=TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source: local data frame [102,888 x 3]
## Groups: document [14,958]
## 
##    document                      word     n
##       &amp;lt;int&amp;gt;                     &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt;
## 1      5932        facewithtearsofjoy    17
## 2      8849                   balloon     8
## 3     12204 blackquestionmarkornament     8
## 4      7697                       nov     7
## 5      7697                       wed     7
## 6     12204 whitequestionmarkornament     7
## 7      2110              sliceofpizza     6
## 8      2452                nailpolish     6
## 9      2741     facewithnogoodgesture     6
## 10     4014                 earofrice     6
## # ... with 102,878 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Counting words so we can make a dtm with our preserved corpus with hashtags and such
tweet_words &amp;lt;- tidy_tweets %&amp;gt;%  
  count(document, word) %&amp;gt;%
  ungroup()

total_words &amp;lt;- tweet_words %&amp;gt;% 
  group_by(document) %&amp;gt;% 
  summarize(total = sum(n))

post_words &amp;lt;- left_join(tweet_words, total_words)

post_words&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 102,888 × 4
##    document           word     n total
##       &amp;lt;int&amp;gt;          &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
## 1         1      #nofilter     1     7
## 2         1  #sanfrancisco     1     7
## 3         1      afternoon     1     7
## 4         1        dolores     1     7
## 5         1           park     2     7
## 6         1             sf     1     7
## 7         2 @publicworkssf     1     5
## 8         2    #dustyrhino     1     5
## 9         2          close     1     5
## 10        2           grin     1     5
## # ... with 102,878 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;new_dtm &amp;lt;- post_words %&amp;gt;% 
  cast_dtm(document, word, n)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This seems to have worked :O :O :O Let’s see how topic modeling works here now…&lt;/p&gt;
&lt;p&gt;Visualization in TIDY form also from &lt;a href=&#34;http://tidytextmining.com/topicmodeling.html&#34;&gt;Silge and Robinson&lt;/a&gt;!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Set parameters for Gibbs sampling (parameters those used in
#Grun and Hornik 2011)
burnin &amp;lt;- 4000
iter &amp;lt;- 2000
thin &amp;lt;- 500
seed &amp;lt;-list(2003,5,63,100001,765)
nstart &amp;lt;- 5
best &amp;lt;- TRUE
k &amp;lt;- 12
test_lda2 &amp;lt;-LDA(new_dtm,k, method=&amp;quot;Gibbs&amp;quot;, 
             control=list(nstart=nstart, seed = seed, best=best, 
                          burnin = burnin, iter = iter, thin=thin))

# Make that TIDY!!! 
test_lda_td2 &amp;lt;- tidy(test_lda2)

lda_top_terms2 &amp;lt;- test_lda_td2 %&amp;gt;%
  group_by(topic) %&amp;gt;%
  top_n(10, beta) %&amp;gt;%
  ungroup() %&amp;gt;%
  arrange(topic, -beta)

lda_top_terms2 %&amp;gt;%
  mutate(term = reorder(term, beta)) %&amp;gt;%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_bar(stat = &amp;quot;identity&amp;quot;, show.legend = FALSE) +
  facet_wrap(~ topic, scales = &amp;quot;free&amp;quot;) +
  coord_flip()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/portfolio/2017-03-09-fun-w-tidy-text_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Still working on connecting assigned topics back to the tweets from whence they came, but as soon as I figure that out I’ll add it! ;)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Name of the work 3</title>
      <link>/portfolio/work3/</link>
      <pubDate>Sat, 05 Nov 2016 19:44:32 +0530</pubDate>
      
      <guid>/portfolio/work3/</guid>
      <description>&lt;p&gt;Fifth abundantly made Give sixth hath. Cattle creature i be don&amp;rsquo;t them.
&lt;/p&gt;

&lt;p&gt;Far far away, behind the word mountains, far from the countries Vokalia and Consonantia, there live the blind texts. Separated they live in Bookmarksgrove right at the coast of the Semantics, a large language ocean.&lt;/p&gt;

&lt;p&gt;A small river named Duden flows by their place and supplies it with the necessary regelialia. It is a paradisematic country, in which roasted parts of sentences fly into your mouth.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;header-level-2&#34;&gt;Header Level 2&lt;/h2&gt;

&lt;p&gt;Even the all-powerful Pointing has no control about the blind texts it is an almost unorthographic life One day however a small line of blind text by the name of Lorem Ipsum decided to leave for the far World of Grammar.&lt;/p&gt;

&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When she reached the first hills of the Italic Mountains, she had a last view back on the skyline of her hometown Bookmarksgrove, the headline of Alphabet Village and the subline of her own road, the Line Lane. Pityful a rethoric question ran over her cheek, then&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Item without image</title>
      <link>/portfolio/work4/</link>
      <pubDate>Sat, 05 Nov 2016 19:50:47 +0530</pubDate>
      
      <guid>/portfolio/work4/</guid>
      <description>&lt;p&gt;Far far away, behind the word mountains, far from the countries Vokalia and Consonantia, there live the blind texts. A small river named Duden flows by their place and supplies it with the necessary regelialia. It is a paradisematic country, in which roasted parts of sentences fly into your mouth.
&lt;/p&gt;

&lt;p&gt;Far far away, behind the word mountains, far from the countries Vokalia and Consonantia, there live the blind texts. Separated they live in Bookmarksgrove right at the coast of the Semantics, a large language ocean.&lt;/p&gt;

&lt;p&gt;A small river named Duden flows by their place and supplies it with the necessary regelialia. It is a paradisematic country, in which roasted parts of sentences fly into your mouth.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;header-level-2&#34;&gt;Header Level 2&lt;/h2&gt;

&lt;p&gt;Even the all-powerful Pointing has no control about the blind texts it is an almost unorthographic life One day however a small line of blind text by the name of Lorem Ipsum decided to leave for the far World of Grammar.&lt;/p&gt;

&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When she reached the first hills of the Italic Mountains, she had a last view back on the skyline of her hometown Bookmarksgrove, the headline of Alphabet Village and the subline of her own road, the Line Lane. Pityful a rethoric question ran over her cheek, then&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Name of the work 5</title>
      <link>/portfolio/work5/</link>
      <pubDate>Sat, 05 Nov 2016 19:53:42 +0530</pubDate>
      
      <guid>/portfolio/work5/</guid>
      <description>&lt;p&gt;Fifth abundantly made Give sixth hath. Cattle creature i be don&amp;rsquo;t them.
&lt;/p&gt;

&lt;p&gt;Far far away, behind the word mountains, far from the countries Vokalia and Consonantia, there live the blind texts. Separated they live in Bookmarksgrove right at the coast of the Semantics, a large language ocean.&lt;/p&gt;

&lt;p&gt;A small river named Duden flows by their place and supplies it with the necessary regelialia. It is a paradisematic country, in which roasted parts of sentences fly into your mouth.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;header-level-2&#34;&gt;Header Level 2&lt;/h2&gt;

&lt;p&gt;Even the all-powerful Pointing has no control about the blind texts it is an almost unorthographic life One day however a small line of blind text by the name of Lorem Ipsum decided to leave for the far World of Grammar.&lt;/p&gt;

&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When she reached the first hills of the Italic Mountains, she had a last view back on the skyline of her hometown Bookmarksgrove, the headline of Alphabet Village and the subline of her own road, the Line Lane. Pityful a rethoric question ran over her cheek, then&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Name of the work 6</title>
      <link>/portfolio/work6/</link>
      <pubDate>Sat, 05 Nov 2016 19:56:17 +0530</pubDate>
      
      <guid>/portfolio/work6/</guid>
      <description>&lt;p&gt;Fifth abundantly made Give sixth hath. Cattle creature i be don&amp;rsquo;t them.
&lt;/p&gt;

&lt;p&gt;Far far away, behind the word mountains, far from the countries Vokalia and Consonantia, there live the blind texts. Separated they live in Bookmarksgrove right at the coast of the Semantics, a large language ocean.&lt;/p&gt;

&lt;p&gt;A small river named Duden flows by their place and supplies it with the necessary regelialia. It is a paradisematic country, in which roasted parts of sentences fly into your mouth.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;header-level-2&#34;&gt;Header Level 2&lt;/h2&gt;

&lt;p&gt;Even the all-powerful Pointing has no control about the blind texts it is an almost unorthographic life One day however a small line of blind text by the name of Lorem Ipsum decided to leave for the far World of Grammar.&lt;/p&gt;

&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When she reached the first hills of the Italic Mountains, she had a last view back on the skyline of her hometown Bookmarksgrove, the headline of Alphabet Village and the subline of her own road, the Line Lane. Pityful a rethoric question ran over her cheek, then&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Name of the work 7</title>
      <link>/portfolio/work7/</link>
      <pubDate>Sat, 05 Nov 2016 19:57:40 +0530</pubDate>
      
      <guid>/portfolio/work7/</guid>
      <description>&lt;p&gt;Fifth abundantly made Give sixth hath. Cattle creature i be don&amp;rsquo;t them.
&lt;/p&gt;

&lt;p&gt;Far far away, behind the word mountains, far from the countries Vokalia and Consonantia, there live the blind texts. Separated they live in Bookmarksgrove right at the coast of the Semantics, a large language ocean.&lt;/p&gt;

&lt;p&gt;A small river named Duden flows by their place and supplies it with the necessary regelialia. It is a paradisematic country, in which roasted parts of sentences fly into your mouth.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;header-level-2&#34;&gt;Header Level 2&lt;/h2&gt;

&lt;p&gt;Even the all-powerful Pointing has no control about the blind texts it is an almost unorthographic life One day however a small line of blind text by the name of Lorem Ipsum decided to leave for the far World of Grammar.&lt;/p&gt;

&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When she reached the first hills of the Italic Mountains, she had a last view back on the skyline of her hometown Bookmarksgrove, the headline of Alphabet Village and the subline of her own road, the Line Lane. Pityful a rethoric question ran over her cheek, then&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Identifying and Visualizing Emojis</title>
      <link>/portfolio/2017-03-10-emoji-maps/</link>
      <pubDate>Thu, 23 Jul 2015 21:13:14 -0500</pubDate>
      
      <guid>/portfolio/2017-03-10-emoji-maps/</guid>
      <description>&lt;p&gt;Dealing with emojis in mined social media data can be tricky for a number of reasons. First, you have to decode them and then… well I guess that is it. After you decode them there is a number of cool things you can look at though!&lt;/p&gt;
&lt;div id=&#34;processing-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Processing the data&lt;/h2&gt;
&lt;p&gt;As mentioned, if you are working with social media data, chances are there will be emojis in that data. You can ‘transform’ these emojis into prose using this code as well as a &lt;a href=&#34;https://github.com/lyons7/emojidictionary&#34;&gt;CSV file&lt;/a&gt; I’ve put together of what all of the emojis look like in R. (The idea for this comes from &lt;a href=&#34;http://opiateforthemass.es/articles/emoticons-in-R/&#34;&gt;Jessica Peterka-Bonetta’s work&lt;/a&gt; – she has a list of emojis as well, but it does not include the newest batch of emojis, Unicode Version 9.0, nor the different skin color options for human-based emojis). If you use this emoji list for your own research, please make sure to acknowledge both myself and Jessica.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;processing-the-data-1&#34; class=&#34;section level2&#34;&gt;

&lt;p&gt;Load in the CSV file. You want to make sure it is located in the correct working directory so R can find it when you tell it to read it in.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tweets=read.csv(&amp;quot;Col_Sep_INSTACORPUS.csv&amp;quot;, header=T)
emoticons &amp;lt;- read.csv(&amp;quot;Decoded Emojis Col Sep.csv&amp;quot;, header = T)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To transform the emojis, you first need to transform your tweet data into ASCII:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tweets$text &amp;lt;- iconv(tweets$text, from = &amp;quot;latin1&amp;quot;, to = &amp;quot;ascii&amp;quot;, 
                    sub = &amp;quot;byte&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;processing-the-data-2&#34; class=&#34;section level2&#34;&gt;
&lt;p&gt;To ‘count’ the emojis you do a find and replace using the CSV file of ‘Decoded Emojis’ as a reference. Here I am using the &lt;a href=&#34;http://www.inside-r.org/packages/cran/DataCombine/docs/FindReplace&#34;&gt;DataCombine package&lt;/a&gt;. What this does is identifies emojis in the tweeted Instagram posts and then replaces them with a prose version. I used whatever description pops up when hovering one’s cursor over an emoji on an Apple emoji keyboard. If not completely the same as other platforms, it provides enough information to find the emoji in question if you are not sure which one was used in the post.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(DataCombine)
tweets &amp;lt;- FindReplace(data = tweets, Var = &amp;quot;text&amp;quot;, 
                      replaceData = emoticons,
                      from = &amp;quot;R_Encoding&amp;quot;, to = &amp;quot;Name&amp;quot;, 
                      exact = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I’m going to subset the data to just look at those posts that have emojis in them. I got help in doing this from &lt;a href=&#34;http://stackoverflow.com/questions/26319567/use-grepl-to-search-either-of-multiple-substrings-in-a-text-in-r&#34;&gt;here&lt;/a&gt;. Again I use my emoji dictionary available &lt;a href=&#34;https://github.com/lyons7/emojidictionary&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;emoticons &amp;lt;- read.csv(&amp;quot;Decoded Emojis Col Sep.csv&amp;quot;, header = T)
emogrepl &amp;lt;- grepl(paste(emoticons$Name, collapse = &amp;quot;|&amp;quot;), tweets$text)
emogreplDF&amp;lt;-as.data.frame(emogrepl)
tweets$ID7 &amp;lt;- 1:nrow(tweets)
emogreplDF$ID7 &amp;lt;- 1:nrow(emogreplDF)
tweets &amp;lt;- merge(tweets,emogreplDF,by=&amp;quot;ID7&amp;quot;)
emosub &amp;lt;- tweets[tweets$emogrepl == &amp;quot;TRUE&amp;quot;, ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that you have a subset of emojis you can compare posts with emojis vs. posts without etc. etc.!&lt;/p&gt;
&lt;p&gt;How about subsetting BY emoji? Let’s look just at posts that have certain emojis in them, like the red heart emoji or the face with tears of joy.&lt;/p&gt;
&lt;p&gt;First we do pattern matching and replacement. The first command looks through the text of the emosub data frame and finds all instances in which the string ‘HEAVYBLACKHEART’ is present and then generates a list of T/F values&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heartgrepl &amp;lt;- grepl(paste(&amp;quot; HEAVYBLACKHEART &amp;quot;), emosub$text)
# Turn that list of T/F values into a data frame so we can link it back to the original posts
heartgreplDF&amp;lt;-as.data.frame(heartgrepl)
# Make a new row so as to smush them together (the T/F designation and your data frame of posts)
emosub$ID7 &amp;lt;- 1:nrow(emosub)
heartgreplDF$ID7 &amp;lt;- 1:nrow(heartgreplDF)
emosub &amp;lt;- merge(emosub,heartgreplDF,by=&amp;quot;ID7&amp;quot;)
redheart &amp;lt;- emosub[emosub$heartgrepl == &amp;quot;TRUE&amp;quot;, ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s do the same with FACEWITHTEARSOFJOY&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lolfacegrepl &amp;lt;- grepl(paste(&amp;quot; FACEWITHTEARSOFJOY &amp;quot;), emosub$text)
lolfacegreplDF&amp;lt;-as.data.frame(lolfacegrepl)
emosub$ID7 &amp;lt;- 1:nrow(emosub)
lolfacegreplDF$ID7 &amp;lt;- 1:nrow(lolfacegreplDF)
emosub &amp;lt;- merge(emosub,lolfacegreplDF,by=&amp;quot;ID7&amp;quot;)
lolface &amp;lt;- emosub[emosub$lolfacegrepl == &amp;quot;TRUE&amp;quot;, ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now FACEWITHHEARTSHAPEDEYES&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hearteyesgrepl &amp;lt;- grepl(paste(&amp;quot; SMILINGFACEWITHHEARTSHAPEDEYES &amp;quot;), emosub$text)
hearteyesgreplDF&amp;lt;-as.data.frame(hearteyesgrepl)
emosub$ID7 &amp;lt;- 1:nrow(emosub)
hearteyesgreplDF$ID7 &amp;lt;- 1:nrow(hearteyesgreplDF)
emosub &amp;lt;- merge(emosub,hearteyesgreplDF,by=&amp;quot;ID7&amp;quot;)
hearteyes &amp;lt;- emosub[emosub$hearteyesgrepl == &amp;quot;TRUE&amp;quot;, ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Sparkles!!!!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sparklesgrepl &amp;lt;- grepl(paste(&amp;quot; SPARKLES &amp;quot;), emosub$text)
sparklesgreplDF&amp;lt;-as.data.frame(sparklesgrepl)
emosub$ID7 &amp;lt;- 1:nrow(emosub)
sparklesgreplDF$ID7 &amp;lt;- 1:nrow(sparklesgreplDF)
emosub &amp;lt;- merge(emosub,sparklesgreplDF,by=&amp;quot;ID7&amp;quot;)
sparkles &amp;lt;- emosub[emosub$sparklesgrepl == &amp;quot;TRUE&amp;quot;, ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Face savouring delicious food!!!!!!!!!!!!!!!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;savourfoodgrepl &amp;lt;- grepl(paste(&amp;quot; FACESAVOURINGDELICIOUSFOOD &amp;quot;), emosub$text)
savourfoodgreplDF&amp;lt;-as.data.frame(savourfoodgrepl)
emosub$ID7 &amp;lt;- 1:nrow(emosub)
savourfoodgreplDF$ID7 &amp;lt;- 1:nrow(savourfoodgreplDF)
emosub &amp;lt;- merge(emosub,savourfoodgreplDF,by=&amp;quot;ID7&amp;quot;)
savourfood &amp;lt;- emosub[emosub$savourfoodgrepl == &amp;quot;TRUE&amp;quot;, ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s have a little fun and try to map where some of these emojis occur. I am using the &lt;a href=&#34;https://github.com/dill/emoGG&#34;&gt;emoGG&lt;/a&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# devtools::install_github(&amp;quot;dill/emoGG&amp;quot;)
library(emoGG)
# Find the emojis we want to use for a graph (might take a few times to get your search query right)
emoji_search(&amp;quot;heart face&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                             emoji  code    keyword
## 1                        grinning 1f600       face
## 5                            grin 1f601       face
## 9                             joy 1f602       face
## 15                         smiley 1f603       face
## 19                          smile 1f604       face
## 26                    sweat_smile 1f605       face
## 35                       laughing 1f606       face
## 37                       innocent 1f607       face
## 46                           wink 1f609       face
## 50                          blush 1f60a       face
## 58                        relaxed  263a       face
## 66                            yum 1f60b       face
## 69                       relieved 1f60c       face
## 74                     heart_eyes 1f60d       face
## 81                     sunglasses 1f60e       face
## 86                          smirk 1f60f       face
## 94                 expressionless 1f611       face
## 102                         sweat 1f613       face
## 107                       pensive 1f614       face
## 112                      confused 1f615       face
## 117                    confounded 1f616       face
## 124                       kissing 1f617       face
## 128                 kissing_heart 1f618       face
## 134          kissing_smiling_eyes 1f619       face
## 138           kissing_closed_eyes 1f61a       face
## 144              stuck_out_tongue 1f61b       face
## 150  stuck_out_tongue_winking_eye 1f61c       face
## 156  stuck_out_tongue_closed_eyes 1f61d       face
## 161                  disappointed 1f61e       face
## 165                       worried 1f61f       face
## 169                         angry 1f620       face
## 176                           cry 1f622       face
## 181                     persevere 1f623       face
## 186                       triumph 1f624       face
## 191         disappointed_relieved 1f625       face
## 195                      frowning 1f626       face
## 198                     anguished 1f627       face
## 201                       fearful 1f628       face
## 207                         weary 1f629       face
## 213                        sleepy 1f62a       face
## 221                     grimacing 1f62c       face
## 224                           sob 1f62d       face
## 230                    open_mouth 1f62e       face
## 234                        hushed 1f62f       face
## 237                    cold_sweat 1f630       face
## 239                        scream 1f631       face
## 243                    astonished 1f632       face
## 247                       flushed 1f633       face
## 251                      sleeping 1f634       face
## 259                      no_mouth 1f636       face
## 261                          mask 1f637       face
## 513                           ear 1f442       face
## 514                           ear 1f442       hear
## 515                           ear 1f442      sound
## 516                           ear 1f442     listen
## 526                          kiss 1f48b       face
## 1467                        heart  2764       love
## 1468                        heart  2764       like
## 1469                        heart  2764 valentines
## 1502                        cupid 1f498      heart
## 1667                          art 1f3a8     design
## 1668                          art 1f3a8      paint
## 1669                          art 1f3a8       draw
## 2733                            a 1f170 red-square
## 2734                            a 1f170   alphabet
## 2735                            a 1f170     letter
## 3358                       bowtie             face
## 3366                    neckbeard             face&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# We find the code &amp;quot;1f60d&amp;quot; for the smiling face with heart shaped eyes. Let&amp;#39;s try to graph this on a map!
# Using the ggmap package here
map &amp;lt;- get_map(location = &amp;#39;Capp St. and 20th, San Francisco,
               California&amp;#39;, zoom = 15)

lat &amp;lt;- hearteyes$latitude
lon &amp;lt;- hearteyes$longitude

# Without the background
# mapPointshearteyes &amp;lt;-  ggplot(hearteyes, aes(lon,lat)) + geom_emoji(emoji=&amp;quot;1f60d&amp;quot;)
mapPointshearteyes &amp;lt;- ggmap(map) + geom_emoji(aes(x = lon, y = lat), 
                                     data=hearteyes, emoji=&amp;quot;1f60d&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mapPointshearteyes&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/portfolio/2017-03-10-emoji-maps_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now let’s try multiple emojis at once (help from &lt;a href=&#34;http://blog.revolutionanalytics.com/2015/11/emojis-in-ggplot-graphics.html&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Can we do this with plain old layering?
# emoji_search(&amp;quot;sparkles&amp;quot;)
# sparkles = &amp;quot;2728&amp;quot;
# red heart = &amp;quot;2764&amp;quot; 

mapPointsmulti &amp;lt;- ggmap(map) + geom_emoji(aes(x = lon, y = lat), 
                                     data=hearteyes, emoji=&amp;quot;1f60d&amp;quot;) +
                              geom_emoji(aes(x=sparkles$longitude, y=sparkles$latitude),
                                     data=sparkles, emoji=&amp;quot;2728&amp;quot;) +
                              geom_emoji(aes(x=redheart$longitude, y=redheart$latitude),
                                     data=redheart, emoji=&amp;quot;2764&amp;quot;)

mapPointsmulti&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/portfolio/2017-03-10-emoji-maps_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;How about emojis that are associated with food?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# apparently called the &amp;#39;yum&amp;#39; emoji: 1f60b

mapPointssavourface &amp;lt;- ggmap(map) + geom_emoji(aes(x=savourfood$longitude,y=savourfood$latitude), 
                                     data=savourfood, emoji=&amp;quot;1f60b&amp;quot;)

mapPointssavourface&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/portfolio/2017-03-10-emoji-maps_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Name of the work 8</title>
      <link>/portfolio/work8/</link>
      <pubDate>Sat, 05 Nov 2016 19:59:22 +0530</pubDate>
      
      <guid>/portfolio/work8/</guid>
      <description>&lt;p&gt;Fifth abundantly made Give sixth hath. Cattle creature i be don&amp;rsquo;t them.
&lt;/p&gt;

&lt;p&gt;Far far away, behind the word mountains, far from the countries Vokalia and Consonantia, there live the blind texts. Separated they live in Bookmarksgrove right at the coast of the Semantics, a large language ocean.&lt;/p&gt;

&lt;p&gt;A small river named Duden flows by their place and supplies it with the necessary regelialia. It is a paradisematic country, in which roasted parts of sentences fly into your mouth.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;header-level-2&#34;&gt;Header Level 2&lt;/h2&gt;

&lt;p&gt;Even the all-powerful Pointing has no control about the blind texts it is an almost unorthographic life One day however a small line of blind text by the name of Lorem Ipsum decided to leave for the far World of Grammar.&lt;/p&gt;

&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When she reached the first hills of the Italic Mountains, she had a last view back on the skyline of her hometown Bookmarksgrove, the headline of Alphabet Village and the subline of her own road, the Line Lane. Pityful a rethoric question ran over her cheek, then&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Item with image</title>
      <link>/portfolio/work9/</link>
      <pubDate>Sat, 05 Nov 2016 20:02:19 +0530</pubDate>
      
      <guid>/portfolio/work9/</guid>
      <description>&lt;p&gt;Far far away, behind the word mountains, far from the countries Vokalia and Consonantia, there live the blind texts. A small river named Duden flows by their place and supplies it with the necessary regelialia. It is a paradisematic country, in which roasted parts of sentences fly into your mouth.
&lt;/p&gt;

&lt;p&gt;Far far away, behind the word mountains, far from the countries Vokalia and Consonantia, there live the blind texts. Separated they live in Bookmarksgrove right at the coast of the Semantics, a large language ocean.&lt;/p&gt;

&lt;p&gt;A small river named Duden flows by their place and supplies it with the necessary regelialia. It is a paradisematic country, in which roasted parts of sentences fly into your mouth.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;header-level-2&#34;&gt;Header Level 2&lt;/h2&gt;

&lt;p&gt;Even the all-powerful Pointing has no control about the blind texts it is an almost unorthographic life One day however a small line of blind text by the name of Lorem Ipsum decided to leave for the far World of Grammar.&lt;/p&gt;

&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When she reached the first hills of the Italic Mountains, she had a last view back on the skyline of her hometown Bookmarksgrove, the headline of Alphabet Village and the subline of her own road, the Line Lane. Pityful a rethoric question ran over her cheek, then&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Item with image</title>
      <link>/portfolio/work10/</link>
      <pubDate>Sat, 05 Nov 2016 20:22:08 +0530</pubDate>
      
      <guid>/portfolio/work10/</guid>
      <description>&lt;p&gt;Far far away, behind the word mountains, far from the countries Vokalia and Consonantia, there live the blind texts. A small river named Duden flows by their place and supplies it with the necessary regelialia. It is a paradisematic country, in which roasted parts of sentences fly into your mouth.
&lt;/p&gt;

&lt;p&gt;Far far away, behind the word mountains, far from the countries Vokalia and Consonantia, there live the blind texts. Separated they live in Bookmarksgrove right at the coast of the Semantics, a large language ocean.&lt;/p&gt;

&lt;p&gt;A small river named Duden flows by their place and supplies it with the necessary regelialia. It is a paradisematic country, in which roasted parts of sentences fly into your mouth.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;header-level-2&#34;&gt;Header Level 2&lt;/h2&gt;

&lt;p&gt;Even the all-powerful Pointing has no control about the blind texts it is an almost unorthographic life One day however a small line of blind text by the name of Lorem Ipsum decided to leave for the far World of Grammar.&lt;/p&gt;

&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When she reached the first hills of the Italic Mountains, she had a last view back on the skyline of her hometown Bookmarksgrove, the headline of Alphabet Village and the subline of her own road, the Line Lane. Pityful a rethoric question ran over her cheek, then&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Item with image</title>
      <link>/portfolio/work11/</link>
      <pubDate>Sat, 05 Nov 2016 20:23:59 +0530</pubDate>
      
      <guid>/portfolio/work11/</guid>
      <description>&lt;p&gt;Far far away, behind the word mountains, far from the countries Vokalia and Consonantia, there live the blind texts. A small river named Duden flows by their place and supplies it with the necessary regelialia. It is a paradisematic country, in which roasted parts of sentences fly into your mouth.
&lt;/p&gt;

&lt;p&gt;Far far away, behind the word mountains, far from the countries Vokalia and Consonantia, there live the blind texts. Separated they live in Bookmarksgrove right at the coast of the Semantics, a large language ocean.&lt;/p&gt;

&lt;p&gt;A small river named Duden flows by their place and supplies it with the necessary regelialia. It is a paradisematic country, in which roasted parts of sentences fly into your mouth.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;header-level-2&#34;&gt;Header Level 2&lt;/h2&gt;

&lt;p&gt;Even the all-powerful Pointing has no control about the blind texts it is an almost unorthographic life One day however a small line of blind text by the name of Lorem Ipsum decided to leave for the far World of Grammar.&lt;/p&gt;

&lt;p&gt;The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn&amp;rsquo;t listen. She packed her seven versalia, put her initial into the belt and made herself on the way.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Lorem ipsum dolor sit amet, consectetuer adipiscing elit.&lt;/li&gt;
&lt;li&gt;Aliquam tincidunt mauris eu risus.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When she reached the first hills of the Italic Mountains, she had a last view back on the skyline of her hometown Bookmarksgrove, the headline of Alphabet Village and the subline of her own road, the Line Lane. Pityful a rethoric question ran over her cheek, then&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>